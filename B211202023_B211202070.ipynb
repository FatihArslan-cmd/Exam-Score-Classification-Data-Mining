{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7pQP1t0DSxwQ",
   "metadata": {
    "id": "7pQP1t0DSxwQ"
   },
   "source": [
    "##  Data Mining Project (2025-2026)\n",
    "*Fatih Arslan B211202023, Yusuf İnan B211202070\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nvtLHSN3MPDL",
   "metadata": {
    "id": "nvtLHSN3MPDL"
   },
   "source": [
    "##  Problem Definition\n",
    "In this project, we analyze students' performance based on their exam scores and background information.\n",
    "\n",
    "##  Dataset Information\n",
    "\n",
    "The dataset, [Students Performance in Exams](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams), named **\"StudentsPerformance.csv\"**, includes data from **1,000 students**.  \n",
    "It contains various features such as:\n",
    "\n",
    "- **Gender**  \n",
    "- **Race/Ethnicity**  \n",
    "- **Parental Level of Education**  \n",
    "- **Lunch Type**  \n",
    "- **Test Preparation Course**  \n",
    "- **Math Score**  \n",
    "- **Reading Score**  \n",
    "- **Writing Score**\n",
    "\n",
    "These features are used to analyze and predict the overall student performance levels.\n",
    "\n",
    "\n",
    "##  Selected Method\n",
    "We apply a Classification method using Random Forest to predict the performance level of students (low, medium, high)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eOwWs3DSMJ47",
   "metadata": {
    "id": "eOwWs3DSMJ47"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0daec",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1762451361102,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "7fc0daec"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wd4dS6ybCMb8",
   "metadata": {
    "id": "wd4dS6ybCMb8"
   },
   "source": [
    "### 1. Importing Required Libraries\n",
    "\n",
    "In this step, I import the necessary Python libraries for data analysis and machine learning.\n",
    "\n",
    "- **pandas** and **numpy** are used for data handling and calculations.  \n",
    "- **matplotlib** and **seaborn** are used for data visualization.  \n",
    "- **sklearn.model_selection** is used for splitting the dataset into training and testing sets.  \n",
    "- **sklearn.preprocessing** includes tools for encoding and scaling the data.  \n",
    "- **RandomForestClassifier** is used to build the classification model.  \n",
    "- **classification_report** and **confusion_matrix** are used to evaluate the model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1YN2gpkOY-zr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1762451361242,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "1YN2gpkOY-zr",
    "outputId": "c903dbf5-a92e-4e76-cb98-fcea82448313"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/hunte/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JAkZ_aCfCeZN",
   "metadata": {
    "id": "JAkZ_aCfCeZN"
   },
   "source": [
    "### 2. Loading and Exploring the Dataset\n",
    "\n",
    "In this step, I load the **StudentsPerformance.csv** dataset using `pandas`.  \n",
    "- `df.head()` shows the first few rows of the dataset.  \n",
    "- `df.info()` gives general information such as column names, data types, and number of non-null values.  \n",
    "- `df.describe()` provides basic statistical details like mean, min, max, and standard deviation for numeric columns.  \n",
    "\n",
    "From the output, we can see that the dataset has **1000 rows** and **8 columns**, with no missing values.  \n",
    "There are 5 categorical columns and 3 numerical columns (math, reading, and writing scores).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GFqtKOgBZHrc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1762451361252,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "GFqtKOgBZHrc",
    "outputId": "1a79104f-2389-4e11-e3e7-7596fba9d2c5"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wp7gXURuC1lV",
   "metadata": {
    "id": "Wp7gXURuC1lV"
   },
   "source": [
    "### 3. Checking for Missing Values\n",
    "\n",
    "In this step, I use `df.isnull().sum()` to check if there are any missing values in the dataset.  \n",
    "The result shows that all columns have **0 missing values**, which means the dataset is complete and does not require data cleaning for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rbfl2jnLaCWa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1762451361792,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "Rbfl2jnLaCWa",
    "outputId": "c4ef17f9-c6e9-4628-e367-b8e46d2659dd"
   },
   "outputs": [],
   "source": [
    "# Calculate average score from math, reading, and writing\n",
    "df[\"average_score\"] = df[[\"math score\", \"reading score\", \"writing score\"]].mean(axis=1)\n",
    "\n",
    "# Categorize students by performance level\n",
    "def categorize(score):\n",
    "    if score >= 85:\n",
    "        return \"high\"\n",
    "    elif score >= 70:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "df[\"performance_level\"] = df[\"average_score\"].apply(categorize)\n",
    "\n",
    "# Group by performance level and calculate summary stats\n",
    "category_table = df.groupby(\"performance_level\").agg(\n",
    "    student_count=(\"performance_level\", \"count\"),\n",
    "    average_score=(\"average_score\", \"mean\")\n",
    ").sort_values(by=\"average_score\", ascending=False)\n",
    "\n",
    "# Format values and add percentage\n",
    "category_table[\"average_score\"] = category_table[\"average_score\"].round(2)\n",
    "category_table = category_table.reset_index()\n",
    "category_table[\"percentage\"] = (category_table[\"student_count\"] / len(df) * 100).round(1).astype(str) + \"%\"\n",
    "\n",
    "# Display summary table\n",
    "print(\"\\n=== Student Performance Analysis ===\\n\")\n",
    "print(category_table.to_string(index=False))\n",
    "print(f\"\\nTotal Students: {len(df)}\")\n",
    "\n",
    "# Plot bar and pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "# Bar chart: Number of students by performance level\n",
    "axes[0].bar(category_table[\"performance_level\"], category_table[\"student_count\"], color=colors)\n",
    "axes[0].set_title('Number of Students by Performance Level', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Performance Level', fontsize=11)\n",
    "axes[0].set_ylabel('Number of Students', fontsize=11)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(category_table[\"student_count\"]):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart: Student distribution by percentage\n",
    "axes[1].pie(\n",
    "    category_table[\"student_count\"],\n",
    "    labels=category_table[\"performance_level\"],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 11, 'fontweight': 'bold'}\n",
    ")\n",
    "axes[1].set_title('Student Distribution by Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "--C4AfPuNzgx",
   "metadata": {
    "id": "--C4AfPuNzgx"
   },
   "source": [
    "## 4. Data Analysis and Visualization\n",
    "\n",
    "This code calculates the average score of students, classifies them into performance levels (high, medium, low),  \n",
    "and visualizes the results using bar and pie charts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "odTo00LuaMdz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 954
    },
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1762451362387,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "odTo00LuaMdz",
    "outputId": "a8bf78be-bc45-4b2a-f2f8-fa7b35811ac9"
   },
   "outputs": [],
   "source": [
    "# Define the education level order\n",
    "education_order = [\n",
    "    \"some high school\",\n",
    "    \"high school\",\n",
    "    \"some college\",\n",
    "    \"associate's degree\",\n",
    "    \"bachelor's degree\",\n",
    "    \"master's degree\"\n",
    "]\n",
    "\n",
    "# Convert column to ordered categorical type\n",
    "df[\"parental level of education\"] = pd.Categorical(\n",
    "    df[\"parental level of education\"],\n",
    "    categories=education_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Set figure and style\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create boxplot\n",
    "ax = sns.boxplot(\n",
    "    x=\"parental level of education\",\n",
    "    y=\"average_score\",\n",
    "    hue=\"parental level of education\",\n",
    "    data=df.dropna(subset=[\"parental level of education\"]),\n",
    "    palette=\"viridis\",\n",
    "    linewidth=2.5,\n",
    "    fliersize=5,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Calculate medians (observed=True prevents future warning)\n",
    "medians = df.groupby(\"parental level of education\", observed=True)[\"average_score\"].median()\n",
    "\n",
    "# Display median values on the plot\n",
    "for i, edu_level in enumerate(education_order):\n",
    "    if edu_level in medians.index:\n",
    "        median_val = medians[edu_level]\n",
    "        ax.text(i, median_val, f'{median_val:.1f}',\n",
    "                ha='center', va='bottom', fontweight='bold',\n",
    "                color='red', fontsize=10)\n",
    "\n",
    "# Customize labels and title\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.xlabel(\"Parental Education Level\", fontsize=13, fontweight='bold')\n",
    "plt.ylabel(\"Average Score\", fontsize=13, fontweight='bold')\n",
    "plt.title(\"Student Performance by Parental Education Level\",\n",
    "          fontsize=15, fontweight='bold', pad=20)\n",
    "\n",
    "# Set limits and grid\n",
    "plt.ylim(0, 105)\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== Statistics by Parental Education Level ===\\n\")\n",
    "summary = df.groupby(\"parental level of education\", observed=True)[\"average_score\"].agg([\n",
    "    ('Student Count', 'count'),\n",
    "    ('Mean', 'mean'),\n",
    "    ('Median', 'median'),\n",
    "    ('Std. Dev', 'std'),\n",
    "    ('Min', 'min'),\n",
    "    ('Max', 'max')\n",
    "]).round(2)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o_bxFJF1OKHj",
   "metadata": {
    "id": "o_bxFJF1OKHj"
   },
   "source": [
    "## 5. Relationship Between Parental Education and Student Performance\n",
    "\n",
    "This section analyzes how parents' education levels affect students' average exam scores using boxplots and summary statistics.\n",
    "\n",
    "As the level of parental education increases, we can observe that the average student scores tend to rise, indicating a positive correlation between parental education and student performance. This trend suggests that students whose parents have higher education levels generally perform better academically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3z6AQAYaPIC",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1762451362401,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "a3z6AQAYaPIC"
   },
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for col in [\"gender\", \"race/ethnicity\", \"parental level of education\", \"lunch\", \"test preparation course\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RA1N9w6JOkNm",
   "metadata": {
    "id": "RA1N9w6JOkNm"
   },
   "source": [
    "## 6. Label Encoding\n",
    "\n",
    "This step converts categorical text data (e.g., gender, lunch type) into numerical values so the model can process them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P_seBVU7aRmM",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1762451362412,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "P_seBVU7aRmM"
   },
   "outputs": [],
   "source": [
    "X = df[[\"gender\", \"race/ethnicity\", \"parental level of education\", \"lunch\", \"test preparation course\", \"math score\", \"reading score\", \"writing score\"]]\n",
    "y = df[\"performance_level\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a-RmOtRxPHH6",
   "metadata": {
    "id": "a-RmOtRxPHH6"
   },
   "source": [
    "### 7. Encoding Categorical Features\n",
    "\n",
    "In this code block, we convert categorical columns into numerical values using **Label Encoding**, which is necessary for most machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53WjvNmnaUsU",
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1762451362843,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "53WjvNmnaUsU"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wJLGqYKkPcwG",
   "metadata": {
    "id": "wJLGqYKkPcwG"
   },
   "source": [
    "### 8. Training a Random Forest Classifier and Making Predictions\n",
    "\n",
    "In this code block, we train a **Random Forest Classifier** on the training data and make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_MMBm_FeaXRk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1762451363325,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "_MMBm_FeaXRk",
    "outputId": "52deb1c0-221b-4277-fde9-19de14ce25fa"
   },
   "outputs": [],
   "source": [
    "# Professional Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = np.unique(y_test)\n",
    "\n",
    "# Combine count and percentage\n",
    "labels = [[f'{count}\\n({count/cm[i].sum()*100:.1f}%)'\n",
    "           for j, count in enumerate(row)] for i, row in enumerate(cm)]\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='coolwarm',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'}, linewidths=3, linecolor='white',\n",
    "            square=True, annot_kws={\"size\": 13, \"weight\": \"bold\"})\n",
    "\n",
    "plt.title('Confusion Matrix - Model Performance', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Class', fontsize=13, fontweight='bold', labelpad=10)\n",
    "plt.ylabel('Actual Class', fontsize=13, fontweight='bold', labelpad=10)\n",
    "\n",
    "# Highlight diagonal (correct predictions)\n",
    "for i in range(len(class_names)):\n",
    "    plt.gca().add_patch(plt.Rectangle((i, i), 1, 1, fill=False,\n",
    "                                       edgecolor='lime', lw=4))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0F-fGkiZPihV",
   "metadata": {
    "id": "0F-fGkiZPihV"
   },
   "source": [
    "### 9. Evaluating the Model Performance\n",
    "\n",
    "In this code block, we evaluate the Random Forest model using **classification metrics** and visualize the **confusion matrix**.\n",
    "\n",
    "Accuracy = 0.96 → The model correctly predicted 96% of test samples.\n",
    "\n",
    "Precision: How often the model is correct when it predicts a class.\n",
    "\n",
    "High = 1.00 → No false “High” predictions.\n",
    "\n",
    "Recall: How many actual instances of a class were correctly identified.\n",
    "\n",
    "High = 0.87 → 87% of true “High” were detected.\n",
    "\n",
    "F1-score: Balance between precision and recall; closer to 1 is better.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The model perfectly identifies “Low” performers (108/108).\n",
    "\n",
    "It correctly predicts 20/23 “High” students, misclassifying 3 as “Medium.”\n",
    "\n",
    "It predicts 65/69 “Medium” students correctly, misclassifying 4 as “Low.”\n",
    "\n",
    "Overall, the model is strongest at detecting “Low” performers and has minor confusion between “High” and “Medium.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g5dQrhNtaaQt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1762451364087,
     "user": {
      "displayName": "Fatih Arslan",
      "userId": "03449603524984634100"
     },
     "user_tz": -180
    },
    "id": "g5dQrhNtaaQt",
    "outputId": "2ca2336d-6043-4cdd-bfce-d3054f732a69"
   },
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.RdYlGn(importances / importances.max())\n",
    "colors = colors.tolist()\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=importances,\n",
    "    y=importances.index,\n",
    "    hue=importances.index,\n",
    "    palette=colors,\n",
    "    legend=False,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# Adding value labels\n",
    "for i, (value, name) in enumerate(zip(importances, importances.index)):\n",
    "    percentage = (value / importances.sum()) * 100\n",
    "    ax.text(value + 0.005, i, f'{value:.4f} ({percentage:.1f}%)',\n",
    "            va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.xlabel('Importance Score', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Features', fontsize=13, fontweight='bold')\n",
    "plt.title('Feature Importance of the Model', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "plt.xlim(0, importances.max() * 1.15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed Feature Importance Table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                    DETAILED FEATURE IMPORTANCE REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': importances.index,\n",
    "    'Importance Score': importances.values,\n",
    "    'Percentage (%)': (importances.values / importances.sum() * 100).round(2),\n",
    "    'Cumulative %': (importances.values / importances.sum() * 100).cumsum().round(2),\n",
    "    'Rank': range(1, len(importances) + 1)\n",
    "})\n",
    "\n",
    "print(importance_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary Statistics\n",
    "print(f\"\\n SUMMARY STATISTICS:\")\n",
    "print(f\"   • Total Number of Features: {len(importances)}\")\n",
    "print(f\"   • Most Important Feature: {importances.index[0]} ({importances.values[0]:.4f})\")\n",
    "print(f\"   • Least Important Feature: {importances.index[-1]} ({importances.values[-1]:.4f})\")\n",
    "print(f\"   • Average Importance Score: {importances.mean():.4f}\")\n",
    "print(f\"   • Top 3 Features Total Contribution: {(importances.values[:3].sum() / importances.sum() * 100):.1f}%\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0s0A7cUUPoae",
   "metadata": {
    "id": "0s0A7cUUPoae"
   },
   "source": [
    "### 10. Visualizing and Reporting Feature Importance\n",
    "\n",
    "Based on the results, the most influential features are reading score, writing score, and math score, which together account for 92% of the model's total importance. The remaining features (race/ethnicity, parental level of education, gender, test preparation course, and lunch) have relatively low importance, indicating they contribute much less to the predictions. In short, students' exam scores are the primary factors driving the model's decisions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
